{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "赛题2：基于收支记录判断借贷意愿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据说明\n",
    "#### 收支交易数据 sz_detail.csv\n",
    "记录用户20190101到20190306每一天的交易记录。\n",
    "\n",
    "字段名称\t说明、\n",
    "id\t用户id（int）、\n",
    "sz_id\t收支分类id（智能分类）、\n",
    "rmb_amt\t交易额（正数为收入，负数为支出）、\n",
    "g2_cod\tg2交易代码（原始分类）、\n",
    "prt_dt\t日期\n",
    "#### 类别映射表 trx_cod.csv\n",
    "收支分类id与对应类别中文名。\n",
    "\n",
    "字段名称\t说明、\n",
    "sz_id\t收支分类id、\n",
    "cat1\t一级大类中文名、\n",
    "cat2\t二级分类中文名\n",
    "#### G2交易代码映射表 g2.csv\n",
    "字段名称\t说明、\n",
    "g2_id\t交易代码、\n",
    "g2_nam\t交易中文简称、\n",
    "g2_dnam\t交易中文详情、\n",
    "#### 用户基础属性 cust_bas_inf.csv\n",
    "字段名称\t说明\n",
    "\n",
    "id\t用户id（int）、\n",
    "gender\t性别（F：女，M：男）、\n",
    "age\t年龄、\n",
    "aum227\t2019年2月27日账户剩余资金、\n",
    "aum306\t2019年3月6日账户剩余资金\n",
    "\n",
    "#### 训练数据 train.csv\n",
    "字段名称\t说明\n",
    "\n",
    "id\t用户id（int）、\n",
    "click_w228\t用户在20190228至20190306之间是否点击过（1：点过，0：未点过）\n",
    "#### 预测目标用户 pred_users.csv\n",
    "包含最终需预测的用户id，需要预测该表中所有用户在20190307至20190313之间点击的概率。、\n",
    "字段名称\t说明、\n",
    "id\t用户id（int）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_users = pd.read_csv(\"data/FT_Camp_2/pred_users.csv\")\n",
    "train = pd.read_csv(\"data/FT_Camp_2/train.csv\")\n",
    "cust_bas_inf = pd.read_csv(\"data/FT_Camp_2/cust_bas_inf.csv\")\n",
    "sz_detail = pd.read_csv(\"data/FT_Camp_2/sz_detail.csv\")\n",
    "trx_cod = pd.read_csv(\"data/FT_Camp_2/trx_cod.csv\")\n",
    "g2 = pd.read_csv(\"data/FT_Camp_2/g2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从上一周已点击的用户中查找未点击用户本周点击的可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape[0], pred_users.shape[0], train.shape[0] - pred_users.shape[0])\n",
    "print(cust_bas_inf.shape[1], trx_cod.shape[0], g2.shape[0], cust_bas_inf.shape[1] + g2.shape[0] + trx_cod.shape[0]*2)\n",
    "sz_detail = sz_detail.sort_values(by=[\"id\", \"prt_dt\"], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_index(dictionary, key):\n",
    "    if key in dictionary:\n",
    "        return dictionary[key]\n",
    "    else:\n",
    "        dictionary.update({key:len(dictionary)})\n",
    "        return dictionary[key]\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_flag = True\n",
    "if load_data_flag:\n",
    "    g2_dict = {'NaN':0}\n",
    "    train_np = np.array(train)\n",
    "    trx_cod_list = trx_cod[\"sz_id\"].tolist()\n",
    "    # g2_list = g2[\"g2_id\"].tolist()\n",
    "    result = [[0 for j in range(cust_bas_inf.shape[1] + trx_cod.shape[0] + 361)] for i in range(train_np.shape[0])]\n",
    "    for i in tqdm_notebook(range(train_np.shape[0]), desc='1st loop'):\n",
    "        result[i][0] = train_np[i][1]\n",
    "        temp_inf = cust_bas_inf.loc[cust_bas_inf['id'] == train_np[i][0]]\n",
    "    #     print(temp_inf)\n",
    "        if temp_inf['gender'].values[0] == 'M':\n",
    "            result[i][1] = 1\n",
    "        else:\n",
    "            result[i][1] = 0\n",
    "\n",
    "        if temp_inf['age'].values[0] == '\\\\N':\n",
    "            result[i][2] = 0\n",
    "        else:\n",
    "            result[i][2] = int(temp_inf['age'].values[0])\n",
    "        if temp_inf['aum227'].values[0] == '\\\\N':\n",
    "            result[i][3] = 0\n",
    "        else:\n",
    "            result[i][3] = int(float(temp_inf['aum227'].values[0])//1)\n",
    "        if temp_inf['aum306'].values[0] == '\\\\N':\n",
    "            result[i][4] = 0\n",
    "        else:\n",
    "            result[i][4] = int(float(temp_inf['aum306'].values[0])//1)\n",
    "    #     print(sz_detail.loc[sz_detail['id'] == train_np[i][0], [\"sz_id\", 'rmb_amt']])\n",
    "        for index, row in sz_detail.loc[sz_detail['id'] == train_np[i][0], [\"sz_id\", 'rmb_amt', 'g2_cod']].iterrows():\n",
    "            result[i][5+trx_cod_list.index(row['sz_id'])] += 1\n",
    "    #         result[i][65+trx_cod_list.index(row['sz_id'])] += row['rmb_amt']//1\n",
    "    #         if row['g2_cod'] == row['g2_cod']:\n",
    "            result[i][65+dict_index(g2_dict, row['g2_cod'])] += 1\n",
    "    print(len(g2_dict))\n",
    "    save_obj(g2_dict, 'g2_dict')\n",
    "    np.savetxt('train_libsvm.txt', result, fmt='%s', delimiter=',', newline='\\n')\n",
    "    result = np.array(result)\n",
    "else:\n",
    "    result = np.loadtxt('train_libsvm.txt', int, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_flag = True\n",
    "if load_data_flag:\n",
    "    g2_dict = load_obj('g2_dict')\n",
    "    pred_users = np.array(pred_users)\n",
    "    test_samples = [[0 for j in range(cust_bas_inf.shape[1] + trx_cod.shape[0] + 361 )] for i in range(pred_users.shape[0])]\n",
    "    trx_cod_list = trx_cod[\"sz_id\"].tolist()\n",
    "    for i in tqdm_notebook(range(pred_users.shape[0]), desc='1st loop'):\n",
    "        test_samples[i][0] = 0\n",
    "        temp_inf = cust_bas_inf.loc[cust_bas_inf['id'] == pred_users[i][0]]\n",
    "    #     print(temp_inf)\n",
    "        if temp_inf['gender'].values[0] == 'M':\n",
    "            test_samples[i][1] = 1\n",
    "        else:\n",
    "            test_samples[i][1] = 0\n",
    "        if temp_inf['age'].values[0] == '\\\\N':\n",
    "            test_samples[i][3] = 1\n",
    "        else:\n",
    "            test_samples[i][2] = temp_inf['age'].values[0]\n",
    "        if temp_inf['aum227'].values[0] == '\\\\N':\n",
    "            test_samples[i][3] = 0\n",
    "        else:\n",
    "            test_samples[i][3] = int(float(temp_inf['aum227'].values[0])//1)\n",
    "        if temp_inf['aum306'].values[0] == '\\\\N':\n",
    "            test_samples[i][4] = 0\n",
    "        else:\n",
    "            test_samples[i][4] = int(float(temp_inf['aum306'].values[0])//1)\n",
    "        for index, row in sz_detail.loc[sz_detail['id'] == pred_users[i][0], [\"sz_id\", 'rmb_amt', 'g2_cod']].iterrows():\n",
    "            test_samples[i][5+trx_cod_list.index(row['sz_id'])] += 1\n",
    "            if dict_index(g2_dict, row['g2_cod']) < 360:\n",
    "                test_samples[i][65+dict_index(g2_dict, row['g2_cod'])] += 1\n",
    "    #         test_samples[i][65+trx_cod_list.index(row['sz_id'])] += row['rmb_amt']\n",
    "    test_samples = np.array(test_samples)\n",
    "    np.savetxt('test_samples_libsvm.txt', test_samples, fmt='%s', delimiter=',', newline='\\n')\n",
    "    save_obj(g2_dict, 'g2_dict_pre')\n",
    "else:\n",
    "    test_samples = np.loadtxt('test_samples_libsvm.txt', int, delimiter=',')\n",
    "    # train_similar_id = np.loadtxt('train_similar_id.txt', int, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_preds = [0 for i in range(test_samples.shape[0])]\n",
    "test_fratures = test_samples[:, 1:200]\n",
    "test_labels = test_samples[:, 0]\n",
    "row_indices = np.random.permutation(result.shape[0])\n",
    "# row_indices = row_indices.tolist()\n",
    "# for sub in train_similar_id:\n",
    "#     row_indices.remove(sub)\n",
    "# for num_round_test in range(60, 85):\n",
    "# auc_record = 0\n",
    "r=0\n",
    "for r in range(200):\n",
    "    random.shuffle(row_indices)\n",
    "    train_xgb = result[row_indices[:int(len(row_indices) * 0.9)], :200]\n",
    "    test_xgb = result[row_indices[int(len(row_indices) * 0.9):], :200]\n",
    "\n",
    "    train_X = train_xgb[:, 1:]\n",
    "    train_Y = train_xgb[:, 0]\n",
    "\n",
    "    test_X = test_xgb[:, 1:]\n",
    "    test_Y = test_xgb[:, 0]\n",
    "\n",
    "    xg_train = xgb.DMatrix(train_X, label=train_Y)\n",
    "    xg_val = xgb.DMatrix(test_X, label=test_Y)\n",
    "\n",
    "    p=0\n",
    "    # for p in range(1, 200):\n",
    "        # setup parameters for xgboost\n",
    "    param = {}\n",
    "    param['eta'] = 0.2\n",
    "    param['max_depth'] = 4\n",
    "    param['silent'] = 1\n",
    "    param['nthread'] = 6\n",
    "    param['scale_pos_weight'] = 9\n",
    "    param['eval_metric'] = 'auc'\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    watchlist = [(xg_train, 'train'), (xg_val, 'val')]\n",
    "    num_round = 66\n",
    "\n",
    "    # do the same thing again, but output probabilities\n",
    "#     bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "    bst  = xgb.train(param, xg_train, num_round)\n",
    "    # bst.save_model('temp.model')\n",
    "\n",
    "    xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "    pred_prob = bst.predict(xg_test)\n",
    "    # pred_label = np.argmax(pred_prob, axis=1)\n",
    "\n",
    "    #评价函数\n",
    "    count_click = 0\n",
    "    for i in range(len(test_Y)):\n",
    "        if pred_prob[i] > 0.5 and test_Y[i] == 1:\n",
    "            count_click += 1\n",
    "    #     print(\"count_click\", count_click)\n",
    "    print(r, 'AUC:%.4f' % metrics.roc_auc_score(test_Y,pred_prob), count_click)\n",
    "    #     auc_record += metrics.roc_auc_score(test_Y,pred_prob)\n",
    "    xg_test = xgb.DMatrix(test_fratures, label=test_labels)\n",
    "    pred_prob = bst.predict(xg_test)\n",
    "    sum_preds += pred_prob\n",
    "#     print(num_round_test, auc_record, auc_record/20)\n",
    "#     print(sum_preds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = sum_preds/200\n",
    "preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"data/FT_Camp_2/pred_users.csv\")\n",
    "submit['score'] = preds\n",
    "submit.to_csv('submit_xgb.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
